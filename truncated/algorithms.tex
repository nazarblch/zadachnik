\section{Вероятностные методы в Computer Science}

\subsection{Рандомизированные алгоритмы}



\begin{problem}
\noindent Алгоритм быстрой сортировки основан на парадигме «разделяй и властвуй». Выбирается из элементов массива опорный элемент, относительно которого переупорядочиваются все остальные элементы. Желательно выбрать опорный элемент близким к значению медианы, чтобы он разбивал список на две примерно равные части. Переупорядочивание элементов относительно опорного, происходит так, что все переставленные элементы, лежащие левее опорного, меньше его, а те, что правее -- больше или равны опорному. Далее процедура быстрой сортировки рекурсивно применяется к левому и правому списку для их упорядочивания по отдельности.

Наихудшие входные данные для описанного алгоритма быстрой сортировки (предполагается, что в качестве опорного элемента выбирается последний элемент обрабатываемого массива) -- элементы уже упорядоченные по возрастанию. 
Откуда следует, что асимптотика времени работы быстрой сортировки в худшем случае $\Theta (n^{2} )$.

Оценить время работы алгоритма быстрой сортировки в среднем. 

\begin{ordre}
Получить рекуррентное соотношение для математического ожидания времени работы, введя индикаторную функцию позиции опорного элемента. 
Воспользоваться соотношением:
\[\begin{array}{l} {\sum _{k=1}^{n-1}k\log k \le \log \frac{n}{2} \sum _{k=1}^{\left\lceil \frac{n}{2} \right\rceil -1}k +\log n\sum _{k=\left\lceil \frac{n}{2} \right\rceil }^{n-1}k =} \\ {=\frac{n(n-1)}{2} \log n-\frac{\left\lceil \frac{n}{2} \right\rceil \left(\left\lceil \frac{n}{2} \right\rceil -1\right)}{2} \le \frac{1}{2} n^{2} \log n-\frac{n^{2} }{8} } \end{array}\] 
 
\end{ordre}

Показать неулучшаемость оценки для произвольного алгоритма сортировки. Привести способ сортировки с асимптотикой $O(n \log n)$ в худшем случае.

\end{problem}

\begin{problem}

(Задача поиска k-ой порядковой статистики).
Рекурсивное применение процедуры, основанной на методе быстрой сортировки, позволяет быстро (в среднем) находить k-ую порядковую статистику. Задача вычисления порядковых статистик состоит в следующем: дан список (массив) из $n$ чисел, необходимо найти значение, которое стоит в k-ой позиции в отсортированном в возрастающем порядке списке. 

\noindent Модифицируем алгоритм быстрой сортировки:


 Выбираем опорный элемент. Делим список на две группы. В первой -- элементы меньше опорного, во второй -- больше либо равны.
 Если размер (число элементов) первой группы больше либо равен k, то к ней снова применяется эта процедура. Иначе -- вызывается процедура для второй группы.
 
\noindent Покажите, используя ту же технику, что и при анализе в среднем алгоритма быстрой сортировки, что среднее время работы такого алгоритма линейно.

\begin{ordre}

\noindent Покажите, что выполняется оценка среднего времени работы алгоритма:

\[
E[T(n)]\le E\left\{\sum _{k=1}^{n}X_{k} \left[T\left(\max (k-1,n-k)\right)+O(n)\right] \right\} 
\]
\[ \le \frac{2}{n} \sum _{k=\left\lfloor \frac{n}{2} \right\rfloor }^{n-1}E[T(k)] +O(n)
\]



\end{ordre}

\begin{remark}

Пусть $a\ge 1$ и $b>1$- константы, $f(n)$ - произвольная функция, $T(n)$ - функция, определенная на множестве неотрицательных целых чисел с помощью рекуррентного соотношения: $T(n)=aT\left(\frac{n}{b} \right)+f(n)$

\noindent где выражение $\frac{n}{b} $интерпретируется либо как $\left\lfloor \frac{n}{b} \right\rfloor $, либо как$\left\lceil \frac{n}{b} \right\rceil $. Тогда асимптотическое поведение функции $T(n)$ можно выразить следующим образом. 

\begin{enumerate}
\item  Если $f(n)=O(n^{\log _{b} a-\varepsilon } )$ для некоторой константы $\varepsilon >0$, то $T(n)=\Theta \left(n^{\log _{b} a} \right)$.

\item  Если $f(n)=\Theta \left(n^{\log _{b} a} \right)$, то $T(n)=\Theta \left(n^{\log _{a} b} \lg n\right)$.

\item  Если $f(n)=\Omega (n^{\log _{b} a+\varepsilon } )$ для некоторой константы $\varepsilon >0$, и для некоторой константы $c<1$ и достаточно больших n выполнено: $af\left(\frac{n}{b} \right)\le cf(n)$, то $T(n)=\Theta \left(f(n)\right)$.
\end{enumerate}

\end{remark}
\end{problem}



\begin{problem}

Даны три матрицы $A,B,C$размера $n\times n$. Требуется проверить равенство $AB=C$.

Простой детерминированный алгоритм перемножает матрицы $A$, $B$ и сравнивает результат с $C$. Время работы такого алгоритма при использовании обычного перемножения матриц составляет $O(n^{3} )$, при использовании быстрого - $O(n^{2,376} )$. Вероятностный алгоритм Фрейвалда с односторонней ошибкой проверяет равенство за время $O(n^{2} )$.

Описание вероятностного алгоритма:

\begin{enumerate}
\item \textbf{ }взять случайный вектор $x\in \left\{0,1\right\}^{n} $

\item  вычислить $y=Bx$

\item  вычислить $z=Ay$

\item  вычислить $t=Cx$

\item  если $z=t$ вернуть «да», иначе «нет».
\end{enumerate}

Покажите, что для предъявленного алгоритма выполняется 
\[\begin{array}{l} {P\left\{z=t \vert AB=C\right\}=1,} \\ {P\left\{z \neq t \vert AB\ne C\right\}\ge {\raise0.7ex\hbox{$ 1 $}\!\mathord{\left/ {\vphantom {1 2}} \right. \kern-\nulldelimiterspace}\!\lower0.7ex\hbox{$ 2 $}} .} \end{array}\] 

\begin{ordre} (добавить что надо несколько раз)
Оценить вероятность ошибочного ответа на одной ненулевой строке матрицы $D = AB - C$. 
\end{ordre}

\end{problem}

\begin{problem}

Требуется сравнить две битовые строки $a,b$, потребовав как можно меньше информации от обеих строк. Основная идея -- сравнивать не сами строки, а функции от них. Так сравниваются $a\; mod\; p$ и $b\; mod\; p$, для некоторого простого числа $p$. Для этого требуется передать $2\log _{2} p$ бит информации.

Описание алгоритма сравнения строк:

\begin{enumerate}
\item  Пусть $\left|a\right|=\left|b\right|=n$, $N=n^{2} \log _{2} n^{2} $

\item  Выбираем случайное простое число $p$из интервала $\left[2..N\right]$ 

\item  Выдать «да», если $a\; mod\; p=b\; mod\; p\Leftrightarrow (a-b)\equiv 0\; mod\; p$, иначе выдать «нет».
\end{enumerate}

\noindent  Обоснуйте выбор именно простого числа на шаге 2 и предложите способ его генерации.  

\noindent Покажите что,

\[\begin{array}{l} {P\left\{(a-b)\equiv 0,mod(p)|a=b\right\}=1,} \\ {P\left\{(a-b)\equiv 0,mod(p)|a\ne b\right\}=O\left({\raise0.7ex\hbox{$ 1 $}\!\mathord{\left/ {\vphantom {1 n}} \right. \kern-\nulldelimiterspace}\!\lower0.7ex\hbox{$ n $}} \right),} \end{array}\] 
 
При этом необходимое количество переданных бит равно $O\left(\log _{2} n\right)$.

\begin{ordre}

Воспользоваться асимптотическим законом распределения простых чисел:
\[\mathop{\lim }\limits_{n\to \infty } \frac{\pi \left(n\right)}{{\raise0.7ex\hbox{$ n $}\!\mathord{\left/ {\vphantom {n \ln n}} \right. \kern-\nulldelimiterspace}\!\lower0.7ex\hbox{$ \ln n $}} } =1,\] 
где $\pi \left(n\right)$ - функция распределения простых чисел, равная количеству простых чисел, не превосходящих $n$.

\end{ordre}

\end{problem}



\subsection{Теория информации}

\begin{problem}
Пусть буква $X$ --- дискретная с.в., принимающая значения из алфавита $(x_1,\ldots,x_m)$ с вероятностями $(p_1,\ldots,p_m)$. 
Имеется случайный текст из $n$ букв $X$ (предполагается, что буквы в тексте независимы друг от друга). Общее количество таких 
текстов $2^{n\log m}$. Поэтому можно закодировать все эти слова, используя $n\log m$ бит. Однако, используя то обстоятельство, что 
$(p_1,\ldots,p_m)$ --- в общем случае неравномерное распределение, предложите лучший способ кодирования, основанный 
на усиленном законе больших чисел.
\end{problem}

\begin{ordre}
Пусть $\Omega=\{ \omega:\; \omega=(X_1,X_2,\ldots, X_n),\, X_i\in 1,2,\ldots,m\}$ --- пространство элементарных исходов. 
Вероятность появления слова $\omega=(X_1,X_2,\ldots, X_n)$ равна $p(\omega)=p_{X_1}\cdot\ldots\cdot p_{X_n}$. По теореме Колмогорова об 
у.з.б.ч. 
$$
-\frac{1}{n}\log p(\omega)=-\frac{1}{n}\sum\limits_{i=1}^{n}\log p_{X_i} \xrightarrow{\text{ п.н. }} 
-{\mathbb E}p(\omega)=-\sum\limits_{i=1}^{m}p_i\log p_i=H(p) 
$$
В частности, $\frac{S_n}{n}\xrightarrow{P}H(p)$, где $S_n=-\log p(\omega)=-\sum\limits_{i=1}^{n}\log p_{X_i}$. Это можно записать в виде 

$$
{\mathbb P}\Bigl( \Bigl| \frac{S_n-nH(p)}{n}\Bigr|>\delta \Bigr)  \xrightarrow{n\to\infty} 0 
$$
\end{ordre}

\begin{problem}[о шляпах Тода Эберта (1998) ]

Трех игроков отводят в комнату, где на них надевают (случайно и независимо) белые и черные шляпы. Каждый видит 
цвет других шляп и должен написать на бумажке одно из трех слов: <<белый>>, <<черный>>, <<пас>> 
(не советуясь с другими и не показывая им свою бумажку). Команда выигрывает, если хотя бы один из игроков назвал правильный 
цвет своей шляпы и ни один не назвал неправильного. Как им сговориться, чтобы увеличить шансы? 
Решите эту же задачу, если игроков $n=2^m -1$ $( m\in {\mathbb N} )$. 
\end{problem}

\begin{ordre}
Воспользуйтесь понятием кода Хемминга.
\end{ordre}

\begin{remark}
Докажем для случая трех игроков, что стратегий лучше (вероятность выигрыша больше  $ \frac{3}{4}$) не бывает . 

Единственная информация, которой владеет $i$-й игрок --- это цвета шляп двух других. Поэтому стратегия для $i$-го игрока должна зависеть 
только от этих двух цветов. В каждом случае имется три варианта ответа для игрока: $0$, $1$ или <<пас>>, т.е. всего $3^{12}$ различных 
стратегий. Поскольку есть $8$ вариантов расположения шляп на игроках, более выгодная стратегия должна обеспечивать выигрыш в $7$ вариантах. 
Тогда один из игроков должен угадать свой цвет в $3$ ситуациях. Значит, имеются для него ответы $\alpha_{i_1 j_1}$, 
$\alpha_{i_2 j_2}$, не являющиеся пасами. Но тогда в ситуациях $\overline{\alpha_{i_1 j_1}} i_1 j_1$ и 
$\overline{\alpha_{i_2 j_2}} i_2 j_2$ он ошибется, что противоречит предположению о $7$ выигрышных ситуациях. 

Таким образом, максимальная вероятность выигрыша равна $\frac{3}{4}$. 

\end{remark}

\begin{problem}
Пусть для некоторого пункта (скажем, для г. Долгопрудный) 
вероятность того, что $15$ июня будет дождь, равна $0.4$, а вероятность того, 
что дождя не будет, равна $0.6$. Пусть далее для этого же пункта вероятность 
дождя $15$ октября равна $0.8$, а вероятность отсутствия осадков равна $0.2$. 
Предположим, что определенный метод прогноза погоды $15$ июня оказывается 
верным в $3/5$ всех тех случаев, когда предсказывается дождь 
и в $4/5$ тех случаев, в которых прогнозируется отсутствие осадков. Применительно к 
погоде на $15$ октября этот метод оказывается правильным в $9/10$ тех случаев, 
когда предсказывается дождь, и в половине случаев, когда предсказывается его 
отсутствие. В какой из указанных двух дней прогноз дает нам больше 
информации о реальной погоде?
\end{problem}

\begin{problem}

Пусть казино делает $n$ бросаний, используя распределение вероятностей на бинарных словах длины $n$ $p\left(x\right)$, где $x=\left\{0,1\right\}^{n} $, известное игроку. При этом казино производит выплаты так, как если бы оно использовало распределении $q\left(x\right)$ (то есть выигранная ставка на 0, после выпадения $x$ исходов увеличивается в $\frac{q\left(x\right)}{q\left(x0\right)} $ раз, выигранная ставка на 1, после выпадения $x$ исходов увеличивается в $\frac{q\left(x\right)}{q\left(x1\right)} $ раз, см. семинар). Докажите, что у игрока есть стратегия, логарифм значения капитала которой равен расстоянию Кульбака-Лейблера $\sum _{x\in \left\{0,1\right\}^{n} }p\left(x\right)\log \frac{p\left(x\right)}{q\left(x\right)}  $ между распределениями $p$ и $q$.
\end{problem}



\subsection{Теория игр}
\begin{problem}
Один игрок прячет (зажимает в кулаке) одну или две монеты достоинством 10 рублей. Другой игрок должен отгадать сколько денег у первого спрятано. Если отгадывает, то получает деньги, если нет -- платит 15 рублей. Каковы ``должны'' быть стратегии игроков при многократном повторении игры?

\end{problem}

\begin{problem}
Некто обладает одной облигацией, которую намеревается продать в один из последующих четырех дней, в которых цена облигации 
принимает различные значения, априори неизвестные, но становящиеся известными в начале каждого дня продаж. Предполагается, что 
цены облигации независимы и их перестановки по торговым дням равновозможны. Какова стратегия продавца, состоящая в выборе дня 
продажи облигации и гарантирующая максимальную вероятность того, что он продаст облигацию в день ее наибольшей цены? 
\end{problem}


\begin{problem}
Ведущий приносит два одинаковых конверта и говорит, что в них лежат деньги, причем в одном вдвое больше, чем в другом. Двое участников берут конверты и тайком друг от друга смотрят, сколько в них денег. Затем один говорит другому: «Махнемся не глядя?» (предлагая поменяться конвертами). Стоит ли соглашаться?
\end{problem}


 
 \begin{problem} 
Имеется неизвестное число от 1 до $n$ ($n\ge 2$). Разрешается задавать любые вопросы с ответами ДА/НЕТ. При ответе ДА мы платим 1 рубль, при ответе НЕТ -- 2 рубля. Сколько необходимо и достаточно заплатить для отгадывания числа?
\end{problem}


\begin{problem}[сублинейный приближенный вероятностный алгоритм для 
матричных игр; Григориадис -- Хачиян, 1995]
Рассматривается симметричная 
антагонистическая игра двух лиц X и Y. Смешанные стратегии X и Y будем 
обозначать соответственно $\vec {x}$ и $\vec {y}$. При этом $x_k $ - 
вероятность того, что игрок X выберет стратегию с номером k, аналогично 
определяется $y_k $. Таким образом, $\vec {x},\vec {y}\in S=\left\{ {\vec 
{x}\in {\rm R}^n:\;\;\vec {e}^T\vec {x}=1,\;\vec {x}\ge \vec {0}} \right\}$, 
где $\vec {e}=\left( {1,...,1} \right)^T$. Выигрыш игрока X: $V_X \left( 
{\vec {x},\vec {y}} \right)=\vec {y}^TA\vec {x}$, а выигрыш игрока Y: $V_Y 
\left( {\vec {x},\vec {y}} \right)=-\vec {y}^TA\vec {x}$ (игра 
антагонистическая). Каждый игрок стремится максимизировать свой выигрыш, при 
заданном ходе оппонента. Равновесием Нэша (в смешанных стратегиях) 
называется такая пара стратегий $\left( {\vec {x}^\ast ,\;\vec {y}^\ast } 
\right)$, что
\[
\vec {x}^\ast \in \mbox{Arg}\mathop {\max }\limits_{\vec {x}\in S} \vec 
{y}^{\ast T} A\vec {x},
\quad
\vec {y}^\ast \in \mbox{Arg}\mathop {\min }\limits_{\vec {y}\in S} \vec 
{y}^TA\vec {x}^\ast .
\]
Ценой игры называют $\mathop {\max }\limits_{\vec {x}\in S} \mathop {\min 
}\limits_{\vec {y}\in S} \vec {y}^TA\vec {x}=\mathop {\min }\limits_{\vec 
{y}\in S} \mathop {\max }\limits_{\vec {x}\in S} \vec {y}^TA\vec {x}=\vec 
{y}^{\ast T}A\vec {x}^\ast $. Поскольку, по условию, игра также симметричная, 
то $A=-A^T$ - матрица$n\times n$. С помощью стандартной редукции можно 
свести к этому случаю общий случай произвольной матричной игры. В 
рассматриваемом же случае цена игры (выигрыш игроков в положении равновесия 
Нэша) есть 0, а множества оптимальных стратегий игроков совпадают. Требуется 
найти с точностью $\varepsilon >0$ положение равновесия Нэша (оптимальную 
стратегию), т.е. требуется найти такой вектор $\vec {x}$, что $A\vec {x}\le 
\varepsilon \vec {e}$, $\vec {x}\in S$. Покажите, считая элементы матрицы 
$A$ равномерно ограниченными, скажем, единицей, что приводимый ниже алгоритм 
находит с вероятностью не меньшей $1 \mathord{\left/ {\vphantom {1 2}} 
\right. \kern-\nulldelimiterspace} 2$ (вместо $1 \mathord{\left/ {\vphantom 
{1 2}} \right. \kern-\nulldelimiterspace} 2$ можно взять любое положительное 
число меньшее единицы) такой $\vec {x}$ за время ${\rm O}\left( {\varepsilon 
^{-2}n\log ^2n} \right)$, т.е. в определенном смысле даже не вся матрица (из 
$n^2$ элементов) просматривается. Отметим также, что в классе 
детерминированных алгоритмов, время работы растет с ростом $n$ не медленнее 
чем $\sim n^2$ (эта нижняя оценка получается из информационных соображений). 
Другими словами, никакой детерминированный алгоритм не может также 
асимптотически быстро находить приближенно равновесие Нэша. Точнее говоря, 
описанный ниже вероятностный алгоритм дает почти квадратичное ускорение по 
сравнению с детерминированными.

\underline {\textbf{Алгоритм}}

\begin{enumerate}
\item \textbf{Инициализация:} $\vec {x}=\vec {U}=\vec {0}$, $\vec {p}={\vec {e}} \mathord{\left/ {\vphantom {{\vec {e}} n}} \right. \kern-\nulldelimiterspace} n$, $t=0$.
\item \textbf{Повторить:}
\item \textbf{Счетчик итераций: }$t:=t+1$.
\item \textbf{Датчик случайных чисел:} выбираем $k\in \left\{ {1,...,n} \right\}$ с вероятностью $p_k $.
\item \textbf{Модификация }$\vec {X}$\textbf{: }$X_k :=X_k +1$.
\item \textbf{Модификация }$\vec {U}$\textbf{:} $U_i :=U_i +a_{ik} $, $i=1,...,n$.
\item \textbf{Модификация }$\vec {p}$\textbf{:} $p_i :={p_i \exp \left( {\varepsilon {a_{ik} } \mathord{\left/ {\vphantom {{a_{ik} } 2}} \right. \kern-\nulldelimiterspace} 2} \right)} \mathord{\left/ {\vphantom {{p_i \exp \left( {\varepsilon {a_{ik} } \mathord{\left/ {\vphantom {{a_{ik} } 2}} \right. \kern-\nulldelimiterspace} 2} \right)} {\left( {\sum\limits_{j=1}^n {p_j \exp \left( {\varepsilon {a_{jk} } \mathord{\left/ {\vphantom {{a_{jk} } 2}} \right. \kern-\nulldelimiterspace} 2} \right)} } \right)}}} \right. \kern-\nulldelimiterspace} {\left( {\sum\limits_{j=1}^n {p_j \exp \left( {\varepsilon {a_{jk} } \mathord{\left/ {\vphantom {{a_{jk} } 2}} \right. \kern-\nulldelimiterspace} 2} \right)} } \right)}$, $i=1,...,n$.
\item \textbf{Критерий останова:} если ${\vec {U}} \mathord{\left/ {\vphantom {{\vec {U}} t}} \right. \kern-\nulldelimiterspace} t\le 
\varepsilon \vec {e}$, то останавливаемся и печатаем ${\vec {x}=\vec {X}} \mathord{\left/ {\vphantom {{\vec {x}=\vec {X}} t}} \right. \kern-\nulldelimiterspace} t$.
\end{enumerate}
\textbf{Указание.} Покажите, что с вероятностью не меньшей, чем $1 
\mathord{\left/ {\vphantom {1 2}} \right. \kern-\nulldelimiterspace} 2$ 
алгоритм остановится через $t^\ast =4\varepsilon ^{-2}\ln n$ итераций. Для 
этого введите $P_i \left( t \right)=\exp \left( {{\varepsilon U_i \left( t 
\right)} \mathord{\left/ {\vphantom {{\varepsilon U_i \left( t \right)} 2}} 
\right. \kern-\nulldelimiterspace} 2} \right)$ и $\Phi \left( t 
\right)=\sum\limits_{i=1}^n {P_i \left( t \right)} $. Покажите, что

$M\left[ {\left. {\Phi \left( {t+1} \right)} \right|\vec {P}\left( t \right)} 
\right]=\Phi \left( t \right)\sum\limits_{i,k=1}^n {p_i \left( t \right)} 
p_k \left( t \right)\exp \left( {{\varepsilon a_{ik} } \mathord{\left/ 
{\vphantom {{\varepsilon a_{ik} } 2}} \right. \kern-\nulldelimiterspace} 2} 
\right)$ и $\exp \left( {{\varepsilon a_{ik} } \mathord{\left/ {\vphantom 
{{\varepsilon a_{ik} } 2}} \right. \kern-\nulldelimiterspace} 2} \right)\le 
1+{\varepsilon a_{ik} } \mathord{\left/ {\vphantom {{\varepsilon a_{ik} } 
2}} \right. \kern-\nulldelimiterspace} 2+{\varepsilon ^2} \mathord{\left/ 
{\vphantom {{\varepsilon ^2} 6}} \right. \kern-\nulldelimiterspace} 6$.

Используя это и кососимметричность матрицы $A$, покажите
\[
M\left[ {\Phi \left( {t+1} \right)} \right]\le M\left[ {\Phi \left( t 
\right)} \right]\left( {1+{\varepsilon ^2} \mathord{\left/ {\vphantom 
{{\varepsilon ^2} 6}} \right. \kern-\nulldelimiterspace} 6} \right).
\]
Следовательно, $M\left[ {\Phi \left( t \right)} \right]\le n\exp \left( 
{{t\varepsilon ^2} \mathord{\left/ {\vphantom {{t\varepsilon ^2} 6}} \right. 
\kern-\nulldelimiterspace} 6} \right)$ и $M\left[ {\Phi \left( {t^\ast } 
\right)} \right]\le n^{5 \mathord{\left/ {\vphantom {5 3}} \right. 
\kern-\nulldelimiterspace} 3}$. Отсюда по неравенству Маркова имеем, что 
($n\ge 8)$
\[
P\left( {\Phi \left( {t^\ast } \right)\le n^2} \right)\ge P\left( {\Phi 
\left( {t^\ast } \right)\le 2n^{5 \mathord{\left/ {\vphantom {5 3}} \right. 
\kern-\nulldelimiterspace} 3}} \right)\ge 1 \mathord{\left/ {\vphantom {1 
2}} \right. \kern-\nulldelimiterspace} 2.
\]
Тогда $P\left( {{\varepsilon U_i \left( {t^\ast } \right)} \mathord{\left/ 
{\vphantom {{\varepsilon U_i \left( {t^\ast } \right)} 2}} \right. 
\kern-\nulldelimiterspace} 2\le 2\ln n,\;i=1,...,n} \right)\ge 1 
\mathord{\left/ {\vphantom {1 2}} \right. \kern-\nulldelimiterspace} 2$. 
Откуда уже следует, что $P\left( {\vec {x}\left( {t^\ast } \right)\le 
\varepsilon \vec {e}} \right)\ge 1 \mathord{\left/ {\vphantom {1 2}} \right. 
\kern-\nulldelimiterspace} 2$.
\end{problem}


